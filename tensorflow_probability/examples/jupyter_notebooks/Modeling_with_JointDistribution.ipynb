{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrwVQsM9TiUw"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpDUTVKYTowI"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltPJCG6pAUoc"
   },
   "source": [
    "# Bayesian Modeling with Joint Distribution\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRVR-tGTR31S"
   },
   "source": [
    "`JointDistributionSequential` is a newly introduced distribution-like Class that empowers users to fast prototype Bayesian model. It lets you chain multiple distributions together, and use lambda function to introduce dependencies. This is designed to build small- to medium- size Bayesian models, including many commonly used models like GLMs, mixed effect models, mixture models, and more. It enables all the necessary features for a Bayesian workflow: prior predictive sampling,  It could be plug-in to another larger Bayesian Graphical model or neural network. In this Colab, we will show some examples of how to use `JointDistributionSequential` to achieve your day to day Bayesian workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiR4-VOt9NFX"
   },
   "source": [
    "### Dependencies & Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcJrUr0pF6qM"
   },
   "outputs": [],
   "source": [
    "#@title Install { display-mode: \"form\" }\n",
    "TF_Installation = 'TF2 Nightly (GPU)' #@param ['TF2 Nightly (GPU)', 'TF2 Stable (GPU)', 'TF1 Nightly (GPU)', 'TF1 Stable (GPU)','System']\n",
    "\n",
    "if TF_Installation == 'TF2 Nightly (GPU)':\n",
    "  !pip install -q --upgrade tf-nightly-gpu-2.0-preview\n",
    "  print('Installation of `tf-nightly-gpu-2.0-preview` complete.')\n",
    "elif TF_Installation == 'TF2 Stable (GPU)':\n",
    "  !pip install -q --upgrade tensorflow-gpu==2.0.0-alpha0\n",
    "  print('Installation of `tensorflow-gpu==2.0.0-alpha0` complete.')\n",
    "elif TF_Installation == 'TF1 Nightly (GPU)':\n",
    "  !pip install -q --upgrade tf-nightly-gpu\n",
    "  print('Installation of `tf-nightly-gpu` complete.')\n",
    "elif TF_Installation == 'TF1 Stable (GPU)':\n",
    "  !pip install -q --upgrade tensorflow-gpu\n",
    "  print('Installation of `tensorflow-gpu` complete.')\n",
    "elif TF_Installation == 'System':\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError('Selection Error: Please select a valid '\n",
    "                   'installation option.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9clSiUTiT3G1"
   },
   "outputs": [],
   "source": [
    "#@title Install { display-mode: \"form\" }\n",
    "TFP_Installation = \"Nightly\" #@param [\"Nightly\", \"Stable\", \"System\"]\n",
    "\n",
    "if TFP_Installation == \"Nightly\":\n",
    "  !pip install -q tfp-nightly\n",
    "  print(\"Installation of `tfp-nightly` complete.\")\n",
    "elif TFP_Installation == \"Stable\":\n",
    "  !pip install -q --upgrade tensorflow-probability\n",
    "  print(\"Installation of `tensorflow-probability` complete.\")\n",
    "elif TFP_Installation == \"System\":\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError(\"Selection Error: Please select a valid \"\n",
    "                   \"installation option.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coUnDhkpT5_6"
   },
   "outputs": [],
   "source": [
    "#@title Import and set ups{ display-mode: \"form\" }\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import tf2\n",
    "if not tf2.enabled():\n",
    "  import tensorflow.compat.v2 as tf\n",
    "  tf.enable_v2_behavior()\n",
    "  assert tf2.enabled()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "sns.reset_defaults()\n",
    "#sns.set_style('whitegrid')\n",
    "#sns.set_context('talk')\n",
    "sns.set_context(context='talk',font_scale=0.7)\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "dtype = tf.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nnwjUdVoWN2"
   },
   "source": [
    "### Make things Fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CK9RaDcoYPG"
   },
   "source": [
    "Before we dive in, let's make sure we're using a GPU for this demo.  \n",
    "\n",
    "To do this, select \"Runtime\" -> \"Change runtime type\" -> \"Hardware accelerator\" -> \"GPU\".\n",
    "\n",
    "The following snippet will verify that we have access to a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qP_4Xr8vpA42"
   },
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print('WARNING: GPU device not found.')\n",
    "else:\n",
    "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJRBc_S0ppfE"
   },
   "source": [
    "Note: if for some reason you cannot access a GPU, this colab will still work. (Training will just take longer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D09_HlJgyvmd"
   },
   "source": [
    "## JointDistribution\n",
    "\n",
    "Notes: This distribution class is useful when you just have a simple model. \"Simple\" means chain-like graphs; although the approach technically works for any PGM with degree at most 255 for a single node (Because Python functions can have at most this many args).\n",
    "\n",
    "The basic idea is to have the user specify a list of `callable`s which produce `tfp.Distribution` instances, one for every vertex in their [PGM](https://en.wikipedia.org/wiki/Graphical_model). The `callable` will have at most as many arguments as its index in the list. (For user convenience, aguments will be passed in reverse order of creation.)  Internally we'll \"walk the graph\" simply by passing every previous RV's value into each callable. In so doing we implement the [chain rule of probablity](https://en.wikipedia.org/wiki/Chain_rule_(probability%29#More_than_two_random_variables): $p(\\{x\\}_i^d)=\\prod_i^d p(x_i|x_{<i})$.\n",
    "\n",
    "The idea is pretty simple, even as Python code. Here's the gist:\n",
    "\n",
    "```python\n",
    "# The chain rule of probability, manifest as Python code.\n",
    "def log_prob(rvs, xs):\n",
    "  # xs[:i] is rv[i]'s maximal blanket. `[::-1]` just reverses the list.\n",
    "  return sum(rv(*xs[i-1::-1]).log_prob(xs[i])\n",
    "             for i, rv in enumerate(rvs))\n",
    "```\n",
    "\n",
    "You can find more information from the docstring of `JointDistributionSequential`, but the gist is that you pass a list of distributions to initialize the Class, if some distributions in the list is depending on output from another upstream distribution/variable, you just wrap it with a lambda function. Now let's see how it works in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RG3iyZQnkOR"
   },
   "source": [
    "## (Robust) Linear regression\n",
    "\n",
    "From PyMC3 doc [GLM: Robust Regression with Outlier Detection](https://docs.pymc.io/notebooks/GLM-robust-with-outlier-detection.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12612,
     "status": "ok",
     "timestamp": 1553755678916,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "R4TUrfH0spkO",
    "outputId": "07dc43f0-1287-49df-a119-fadf6962c436"
   },
   "outputs": [],
   "source": [
    "#@title Get data\n",
    "#@markdown Cut & pasted directly from the `fetch_hogg2010test()` function. It is identical to the original dataset as hardcoded in the Hogg 2010 paper\n",
    "dfhogg = pd.DataFrame(np.array([[1, 201, 592, 61, 9, -0.84],\n",
    "                                 [2, 244, 401, 25, 4, 0.31],\n",
    "                                 [3, 47, 583, 38, 11, 0.64],\n",
    "                                 [4, 287, 402, 15, 7, -0.27],\n",
    "                                 [5, 203, 495, 21, 5, -0.33],\n",
    "                                 [6, 58, 173, 15, 9, 0.67],\n",
    "                                 [7, 210, 479, 27, 4, -0.02],\n",
    "                                 [8, 202, 504, 14, 4, -0.05],\n",
    "                                 [9, 198, 510, 30, 11, -0.84],\n",
    "                                 [10, 158, 416, 16, 7, -0.69],\n",
    "                                 [11, 165, 393, 14, 5, 0.30],\n",
    "                                 [12, 201, 442, 25, 5, -0.46],\n",
    "                                 [13, 157, 317, 52, 5, -0.03],\n",
    "                                 [14, 131, 311, 16, 6, 0.50],\n",
    "                                 [15, 166, 400, 34, 6, 0.73],\n",
    "                                 [16, 160, 337, 31, 5, -0.52],\n",
    "                                 [17, 186, 423, 42, 9, 0.90],\n",
    "                                 [18, 125, 334, 26, 8, 0.40],\n",
    "                                 [19, 218, 533, 16, 6, -0.78],\n",
    "                                 [20, 146, 344, 22, 5, -0.56]]),\n",
    "                   columns=['id','x','y','sigma_y','sigma_x','rho_xy'])\n",
    "\n",
    "\n",
    "## for convenience zero-base the 'id' and use as index\n",
    "dfhogg['id'] = dfhogg['id'] - 1\n",
    "dfhogg.set_index('id', inplace=True)\n",
    "\n",
    "## standardize (mean center and divide by 1 sd)\n",
    "dfhoggs = (dfhogg[['x','y']] - dfhogg[['x','y']].mean(0)) / dfhogg[['x','y']].std(0)\n",
    "dfhoggs['sigma_y'] = dfhogg['sigma_y'] / dfhogg['y'].std(0)\n",
    "dfhoggs['sigma_x'] = dfhogg['sigma_x'] / dfhogg['x'].std(0)\n",
    "\n",
    "def plot_hoggs(dfhoggs):\n",
    "  ## create xlims ylims for plotting\n",
    "  xlims = (dfhoggs['x'].min() - np.ptp(dfhoggs['x'])/5,\n",
    "           dfhoggs['x'].max() + np.ptp(dfhoggs['x'])/5)\n",
    "  ylims = (dfhoggs['y'].min() - np.ptp(dfhoggs['y'])/5,\n",
    "           dfhoggs['y'].max() + np.ptp(dfhoggs['y'])/5)\n",
    "\n",
    "  ## scatterplot the standardized data\n",
    "  g = sns.FacetGrid(dfhoggs, size=8)\n",
    "  _ = g.map(plt.errorbar, 'x', 'y', 'sigma_y', 'sigma_x', marker=\"o\", ls='')\n",
    "  _ = g.axes[0][0].set_ylim(ylims)\n",
    "  _ = g.axes[0][0].set_xlim(xlims)\n",
    "\n",
    "  plt.subplots_adjust(top=0.92)\n",
    "  _ = g.fig.suptitle('Scatterplot of Hogg 2010 dataset after standardization', fontsize=16)\n",
    "  return g, xlims, ylims\n",
    "  \n",
    "g = plot_hoggs(dfhoggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLlvnGSk5awL"
   },
   "outputs": [],
   "source": [
    "X_np = dfhoggs['x'].values\n",
    "sigma_y_np = dfhoggs['sigma_y'].values\n",
    "Y_np = dfhoggs['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zixodmz8DMuX"
   },
   "source": [
    "### Conventional OLS Model\n",
    "Now, let's set up a linear model, a simple intercept + slope regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G61a6pDYW82H"
   },
   "outputs": [],
   "source": [
    "mdl_ols = tfd.JointDistributionSequential([\n",
    "    # b0 ~ Normal(0, 1)\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # b1 ~ Normal(0, 1)\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # x ~ Normal(b0+b1*X, 1)\n",
    "    lambda b1, b0: tfd.Normal(\n",
    "      # Parameter transformation\n",
    "      loc=b0 + b1*X_np,\n",
    "      scale=sigma_y_np)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDJca7bNXhDO"
   },
   "source": [
    "You can then check the graph of the model to see the dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12826,
     "status": "ok",
     "timestamp": 1553755679181,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "Isc-CWU1Xgz6",
    "outputId": "9044774e-acba-46aa-a369-cee15155444a"
   },
   "outputs": [],
   "source": [
    "mdl_ols._resolve_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuAzuXmQs-BN"
   },
   "source": [
    "Sampling from the model is quite straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12812,
     "status": "ok",
     "timestamp": 1553755679182,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "rB-jUF4ls8kI",
    "outputId": "d7380512-9c23-4887-cf9f-9ab6b5a35e79"
   },
   "outputs": [],
   "source": [
    "mdl_ols.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnnL-aA7tM9U"
   },
   "source": [
    "...which gives a tuple of tf.Tensor. You can immediately plug it into the log_prob function to compute the log_prob of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12806,
     "status": "ok",
     "timestamp": 1553755679185,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "TwXlvGwYtMPG",
    "outputId": "89875d31-aa65-46c2-d022-b63a810c8891"
   },
   "outputs": [],
   "source": [
    "b0, b1, y = mdl_ols.sample()\n",
    "mdl_ols.log_prob([b0, b1, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ro2HVI5bt6Tx"
   },
   "source": [
    "Hmmm, something is not right here: we should be getting a scalar log_prob! In fact, we can further check to see if something is off by calling the `.log_prob_parts`, which gives the `log_prob` of each nodes in the Graphical model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12798,
     "status": "ok",
     "timestamp": 1553755679189,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "LqQCaMNetKw6",
    "outputId": "f378df07-4507-436c-d0cf-88f9738421e1"
   },
   "outputs": [],
   "source": [
    "mdl_ols.log_prob_parts([b0, b1, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFRT1tTPuaAw"
   },
   "source": [
    "...turns out the last node is not being reduce_sum along the i.i.d. dimension/axis! The trick here is to use `tfd.Independent` to reinterpreted the batch shape (so that the rest of the axis will be reduced correctly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kmo6QgUvtKzv"
   },
   "outputs": [],
   "source": [
    "mdl_ols_ = tfd.JointDistributionSequential([\n",
    "    # b0\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # b1\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # likelihood\n",
    "    #   Using Independent to ensure the log_prob is not incorrectly broadcasted\n",
    "    lambda b1, b0: tfd.Independent(\n",
    "        tfd.Normal(\n",
    "            # Parameter transformation\n",
    "            loc=b0 + b1*X_np,\n",
    "            scale=sigma_y_np),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdqWE_g5v3I3"
   },
   "source": [
    "Now, lets check the last node/distribution of the model, you can see that event shape is now correctly interpreted. Note that it might take a bit of trial and error to get the `reinterpreted_batch_ndims` right, but you can always easily print the distribution or sampled tensor to double check the shape!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13100,
     "status": "ok",
     "timestamp": 1553755679511,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "OLB6Tf20tK2P",
    "outputId": "2653b760-3c8b-43ef-8bd1-e7fd1f64d2a3"
   },
   "outputs": [],
   "source": [
    "print(mdl_ols_.sample_distributions()[0][-1])\n",
    "print(mdl_ols.sample_distributions()[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13080,
     "status": "ok",
     "timestamp": 1553755679514,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "IaECAJ7nvq3u",
    "outputId": "938513b8-1db3-41da-c3eb-2c8d4626254b"
   },
   "outputs": [],
   "source": [
    "b0, b1, y = mdl_ols_.sample()\n",
    "mdl_ols_.log_prob([b0, b1, y])  # <== Getting a scalar correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkcfQAyiwwBO"
   },
   "source": [
    "And we can now do inference! You can use optimizer to find the Maximum likelihood estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9Dqv9dCxFUD"
   },
   "source": [
    "#### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-w0Jha-rxFUG"
   },
   "outputs": [],
   "source": [
    "# Small wrapper to get the neg_log_likelihood that outputs value with gradient\n",
    "def neg_log_likelihood(x):\n",
    "  def neg_log_p(x):\n",
    "    return -tf.squeeze(mdl_ols_.log_prob([x[0], x[1], Y_np]))\n",
    "  return tfp.math.value_and_gradient(neg_log_p, x)\n",
    "\n",
    "lbfgs_results = tfp.optimizer.lbfgs_minimize(\n",
    "    neg_log_likelihood,\n",
    "    initial_position=tf.zeros(2, dtype=dtype),\n",
    "    tolerance=1e-20,\n",
    "    x_tolerance=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14131,
     "status": "ok",
     "timestamp": 1553755680588,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "9vlNNIB0xFUP",
    "outputId": "397aff2f-3a13-42c5-dddd-89e03fdd9dce"
   },
   "outputs": [],
   "source": [
    "b0est, b1est = lbfgs_results.position.numpy()\n",
    "\n",
    "g, xlims, ylims = plot_hoggs(dfhoggs);\n",
    "xrange = np.linspace(xlims[0], xlims[1], 100)\n",
    "g.axes[0][0].plot(xrange, b0est + b1est*xrange, \n",
    "                  color='r', label='MLE of OLE model')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KN4U_48twwDn"
   },
   "source": [
    "#### Batched version model and MCMC\n",
    "\n",
    "In Bayesian Inference, we usually want to work with MCMC samples, as when the samples are from the posterior, we can plug them into *any* function to compute expectations. However, the MCMC API require us to write models that are batch friendly, and we can check that our model is actually not \"batchable\" by calling `sample([...])`\n",
    "\n",
    "```python\n",
    "mdl_ols_.sample(5)  # <== error as some computation could not be done in batch\n",
    "```\n",
    "\n",
    "In this case, it is relatively straightforward as we only have a linear function inside our model, expanding the shape should do the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14097,
     "status": "ok",
     "timestamp": 1553755680590,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "s8yueMOSsWfP",
    "outputId": "1b69b225-b2bc-4016-c6c2-b80dc0cacb32"
   },
   "outputs": [],
   "source": [
    "mdl_ols_batch = tfd.JointDistributionSequential([\n",
    "    # b0\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # b1\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # likelihood\n",
    "    #   Using Independent to ensure the log_prob is not incorrectly broadcasted\n",
    "    lambda b1, b0: tfd.Independent(\n",
    "        tfd.Normal(\n",
    "            # Parameter transformation\n",
    "            loc=b0[:, None] + b1[:, None]*X_np[None, :],\n",
    "            scale=sigma_y_np[None, :]),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    ),\n",
    "])\n",
    "\n",
    "mdl_ols_batch._resolve_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7glduHF62Mu"
   },
   "source": [
    "We can again sample and evaluate the log_prob_parts to do some checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14088,
     "status": "ok",
     "timestamp": 1553755680591,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "j5xx4ZW261pK",
    "outputId": "08f4abb1-ed0a-4a41-e229-a47cbfd7c34f"
   },
   "outputs": [],
   "source": [
    "mdl_ols_batch.sample_distributions(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14079,
     "status": "ok",
     "timestamp": 1553755680592,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "VBcoLQyn7Bj1",
    "outputId": "12ebe398-a613-440b-c2cc-18273774011e"
   },
   "outputs": [],
   "source": [
    "b0, b1, y = mdl_ols_batch.sample(4)\n",
    "mdl_ols_batch.log_prob_parts([b0, b1, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPTIG5w07ZwM"
   },
   "source": [
    "Some side notes:\n",
    "- Now `mdl_ols_batch.sample()` would not work as the model is expecting inputs to be tensors with a batch dimension. You can do `mdl_ols_batch.sample(1)` and squeeze the output (value or log_prob) as a workaround.\n",
    "- We want to work with batch version of the model because it is the fastest for multi-chain MCMC. In cases that you cannot rewrite the model as a batched version (e.g., ODE models), you can map the log_prob function using `tf.map_fn` to achieve the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3q-On2sYj9y"
   },
   "outputs": [],
   "source": [
    "# Small helper function to validate log_prob shape (avoid wrong broadcasting)\n",
    "def validate_log_prob_part(model, batch_shape=1, observed=-1):\n",
    "  samples = model.sample(batch_shape)\n",
    "  logp_part = list(model.log_prob_parts(samples))\n",
    "  \n",
    "  # exclude observed node\n",
    "  logp_part.pop(observed)\n",
    "  for part in logp_part:\n",
    "    tf.assert_equal(part.shape, logp_part[-1].shape)\n",
    "\n",
    "validate_log_prob_part(mdl_ols_batch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14062,
     "status": "ok",
     "timestamp": 1553755680595,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "kHAc1pILpjRD",
    "outputId": "b442dfe7-5c3e-4ac3-96d3-19f903f69daf"
   },
   "outputs": [],
   "source": [
    "#@title More checks: comparing the generated log_prob fucntion with handwrittent TFP log_prob function. { display-mode: \"form\" }\n",
    "\n",
    "def ols_logp_batch(b0, b1, Y):\n",
    "  b0_prior = tfd.Normal(loc=tf.cast(0, dtype), scale=1.) # b0\n",
    "  b1_prior = tfd.Normal(loc=tf.cast(0, dtype), scale=1.) # b1\n",
    "  likelihood = tfd.Normal(loc=b0[:, None] + b1[:, None]*X_np[None, :],\n",
    "                          scale=sigma_y_np[None, :]) # likelihood\n",
    "  return b0_prior.log_prob(b0) +\\\n",
    "         b1_prior.log_prob(b1) +\\\n",
    "         tf.reduce_sum(likelihood.log_prob(Y), axis=-1)\n",
    "\n",
    "b0, b1, x = mdl_ols_batch.sample(4)\n",
    "print(mdl_ols_batch.log_prob([b0, b1, Y_np]).numpy()) \n",
    "print(ols_logp_batch(b0, b1, Y_np).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYfRf23S2cQn"
   },
   "source": [
    "#### MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEjA8P8x-1HP"
   },
   "outputs": [],
   "source": [
    "logp = lambda b0, b1: mdl_ols_batch.log_prob([b0, b1, Y_np])\n",
    "\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def run_chain(number_of_steps = 1000, burnin = 1000, nchain = 4):\n",
    "  b0, b1, _ = mdl_ols_batch.sample(nchain)\n",
    "\n",
    "  def trace_fn(_, pkr):\n",
    "    return (pkr.inner_results.is_accepted,\n",
    "            pkr.inner_results.accepted_results.step_size)\n",
    "\n",
    "  hmc=tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    tfp.mcmc.HamiltonianMonteCarlo(\n",
    "      target_log_prob_fn=logp,\n",
    "      num_leapfrog_steps=3,\n",
    "      step_size=[tf.cast(i, dtype=dtype) for i in [.1, .1]]),\n",
    "      target_accept_prob=tf.cast(.8, dtype=dtype),\n",
    "      # Adapt for the entirety of the trajectory.\n",
    "      num_adaptation_steps=burnin\n",
    "      )\n",
    "\n",
    "  # Sampling from the chain.\n",
    "  mcmc_trace, (is_accepted, step_size) = tfp.mcmc.sample_chain(\n",
    "      num_results = number_of_steps,\n",
    "      num_burnin_steps = burnin,\n",
    "      current_state=[b0, b1],\n",
    "      kernel=hmc,\n",
    "      trace_fn=trace_fn)\n",
    "  return mcmc_trace, is_accepted, step_size\n",
    "\n",
    "\n",
    "# Sample from posterior distribution and get diagnostic\n",
    "mcmc_trace, is_accepted, step_size = run_chain()\n",
    "ess = tfp.mcmc.effective_sample_size(mcmc_trace)\n",
    "rhat = tfp.mcmc.potential_scale_reduction(mcmc_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57308,
     "status": "ok",
     "timestamp": 1553755723873,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "4qQdOPk90f7t",
    "outputId": "ede787e2-828d-4d34-ba87-0ac869203eec"
   },
   "outputs": [],
   "source": [
    "print(\"acceptance rate: {}\".format(is_accepted.numpy().mean()))\n",
    "print(\"final 100 step size: {}\".format(np.asarray(step_size[-100:]).mean(-1)))\n",
    "print(\"The effective sample size is: \")\n",
    "print(np.asarray(ess))\n",
    "print(\"The rhat is: \")\n",
    "print(np.asarray(rhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59429,
     "status": "ok",
     "timestamp": 1553755726007,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "FPPwekE40gAn",
    "outputId": "3692615c-6ffb-4c55-9535-5859c655e125"
   },
   "outputs": [],
   "source": [
    "var_name = ['b0', 'b1']\n",
    "n_var = len(mcmc_trace)\n",
    "_, ax = plt.subplots(n_var, 1, figsize=(12, 3*n_var), sharex=True)\n",
    "for i in range(n_var):\n",
    "  ax[i].plot(mcmc_trace[i].numpy().squeeze(), alpha=.5)\n",
    "  ax[i].set_title(var_name[i])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60132,
     "status": "ok",
     "timestamp": 1553755726733,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "ta-N5ni50gDH",
    "outputId": "8a2e81e0-6496-43f3-cae1-32aa331248fb"
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "b0est, b1est = mcmc_trace[0].numpy().flatten()[-k:, None], mcmc_trace[1].numpy().flatten()[-k:, None]\n",
    "\n",
    "g, xlims, ylims = plot_hoggs(dfhoggs);\n",
    "xrange = np.linspace(xlims[0], xlims[1], 100)[None, :]\n",
    "g.axes[0][0].plot(np.tile(xrange, (k, 1)).T,\n",
    "                  (b0est + b1est*xrange).T,\n",
    "                  alpha=.25, color='r')\n",
    "plt.legend([g.axes[0][0].lines[-1]], ['MCMC OLE model']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDpPn8b4DeOt"
   },
   "source": [
    "### Student-T Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxPJkKHeTEiU"
   },
   "source": [
    "Note that from now on we always work with the batch version of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60107,
     "status": "ok",
     "timestamp": 1553755726734,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "L8dRAwfIDeOv",
    "outputId": "0d1ebd0b-34a1-49c1-c1f9-d5939e70dca2"
   },
   "outputs": [],
   "source": [
    "a, b = tf.cast(1., dtype), tf.cast(100., dtype)\n",
    "mdl_studentt = tfd.JointDistributionSequential([\n",
    "    # b0 ~ Normal(0, 1)\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # b1 ~ Normal(0, 1)\n",
    "    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),\n",
    "    # df ~ Uniform(a, b)\n",
    "    tfd.Uniform(low=a, high=b), # df\n",
    "    # likelihood ~ StudentT(df, f(b0, b1), sigma_y)\n",
    "    #   Using Independent to ensure the log_prob is not incorrectly broadcasted,\n",
    "    #   Note also the use of boilerplate [:, None] to make sure correct shape.\n",
    "    lambda df, b1, b0: tfd.Independent(\n",
    "        tfd.StudentT(\n",
    "            df=df[:, None],\n",
    "            # Parameter transformation\n",
    "            loc=b0[:, None] + b1[:, None]*X_np[None, :],\n",
    "            scale=sigma_y_np[None, :])), # likelihood\n",
    "])\n",
    "\n",
    "mdl_studentt._resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mG3HwG8ubK9a"
   },
   "outputs": [],
   "source": [
    "validate_log_prob_part(mdl_studentt, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GXv22QHqDeO3"
   },
   "source": [
    "#### Forward sample (prior predictive sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60089,
     "status": "ok",
     "timestamp": 1553755726738,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "S_C7cvglDeO5",
    "outputId": "fd03183a-6f83-4acf-e3d3-779e770776a9"
   },
   "outputs": [],
   "source": [
    "b0, b1, df, x = mdl_studentt.sample(1000)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXfsadBpDePA"
   },
   "source": [
    "#### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrORYJ9CDePB"
   },
   "outputs": [],
   "source": [
    "# Interval transformation\n",
    "tfp_interval = tfb.Inline(\n",
    "    inverse_fn=(\n",
    "        lambda x: tf.math.log(x - a) - tf.math.log(b - x)),\n",
    "    forward_fn=(\n",
    "        lambda y: (b - a) * tf.sigmoid(y) + a),\n",
    "    forward_log_det_jacobian_fn=(\n",
    "        lambda x: tf.math.log(b - a) - 2 * tf.nn.softplus(-x) - x),\n",
    "    forward_min_event_ndims=0,\n",
    "    name=\"interval\")\n",
    "\n",
    "# Now that we have a batch version of log_prob function, reduce_sum is needed\n",
    "neg_log_p = lambda x: -tf.reduce_sum(mdl_studentt.log_prob(\n",
    "             [[x[0]], [x[1]], [tfp_interval.inverse(x[2])], Y_np]))\n",
    "\n",
    "def neg_log_likelihood(x):\n",
    "  return tfp.math.value_and_gradient(neg_log_p, x)\n",
    "\n",
    "\n",
    "start = tf.cast(\n",
    "    [0., 0., tfp_interval.forward(np.float64(2.))],\n",
    "    dtype=dtype)\n",
    "\n",
    "lbfgs_results = tfp.optimizer.lbfgs_minimize(\n",
    "    neg_log_likelihood,\n",
    "    initial_position=start,\n",
    "    tolerance=1e-20,\n",
    "    x_tolerance=1e-20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63113,
     "status": "ok",
     "timestamp": 1553755729792,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "BeZI5emtDePC",
    "outputId": "d1f5b2a6-5cbd-4920-e79e-619ea49d88d8"
   },
   "outputs": [],
   "source": [
    "b0est, b1est, dfest = lbfgs_results.position.numpy()\n",
    "\n",
    "g, xlims, ylims = plot_hoggs(dfhoggs);\n",
    "xrange = np.linspace(xlims[0], xlims[1], 100)\n",
    "g.axes[0][0].plot(xrange, b0est + b1est*xrange, \n",
    "                  color='r', label='MLE of StudentT model')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29wTnXQ-DePF"
   },
   "source": [
    "#### MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SRaHxfFUMvB"
   },
   "outputs": [],
   "source": [
    "logp = lambda b0, b1, df: mdl_studentt.log_prob([b0, b1, df, Y_np])\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def run_chain(number_of_steps = 1000, burnin = 1000, nchain = 4):\n",
    "  # random initialization of the starting postion of each chain\n",
    "  b0, b1, df, _ = mdl_studentt.sample(nchain)\n",
    "\n",
    "  # bijector to map contrained parameters to real\n",
    "  unconstraining_bijectors = [\n",
    "      tfb.Identity(),\n",
    "      tfb.Identity(),\n",
    "      tfp_interval,\n",
    "  ]\n",
    "\n",
    "  def trace_fn(_, pkr):\n",
    "    return (pkr.inner_results.inner_results.is_accepted,\n",
    "            pkr.inner_results.inner_results.accepted_results.step_size)\n",
    "\n",
    "  kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "      target_log_prob_fn=logp,\n",
    "      num_leapfrog_steps=3,\n",
    "      step_size=[tf.cast(i, dtype=dtype) for i in [.1, .1, .02]]),\n",
    "    bijector=unconstraining_bijectors)\n",
    "\n",
    "  hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    kernel,\n",
    "    target_accept_prob=tf.cast(.8, dtype=dtype),\n",
    "    # Adapt for the entirety of the burnin.\n",
    "    num_adaptation_steps=burnin\n",
    "    )\n",
    "\n",
    "  # Sampling from the chain.\n",
    "  mcmc_trace, (is_accepted, step_size) = tfp.mcmc.sample_chain(\n",
    "      num_results = number_of_steps,\n",
    "      num_burnin_steps = burnin,\n",
    "      current_state=[b0, b1, tf.ones_like(df, dtype)*1.2],\n",
    "      kernel=hmc,\n",
    "      trace_fn=trace_fn)\n",
    "  return mcmc_trace, is_accepted, step_size\n",
    "\n",
    "# Sample from posterior distribution and get diagnostic\n",
    "mcmc_trace, is_accepted, step_size = run_chain()\n",
    "ess = tfp.mcmc.effective_sample_size(mcmc_trace)\n",
    "rhat = tfp.mcmc.potential_scale_reduction(mcmc_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118003,
     "status": "ok",
     "timestamp": 1553755784704,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "mDJJvUz8xMNO",
    "outputId": "d497710a-29cf-4841-d599-0db2b6574118"
   },
   "outputs": [],
   "source": [
    "print(\"acceptance rate: {}\".format(is_accepted.numpy().mean()))\n",
    "print(\"final 100 step size: {}\".format(np.asarray(step_size[-100:]).mean(-1)))\n",
    "print(\"The effective sample size is: \")\n",
    "print(np.asarray(ess))\n",
    "print(\"The rhat is: \")\n",
    "print(np.asarray(rhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ui9y9B7dW6pI"
   },
   "source": [
    "The samples for `df` is pretty horrible - we will need better tuning of HMC (e.g., NUTS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120395,
     "status": "ok",
     "timestamp": 1553755787109,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "eQ6DzoIqDePS",
    "outputId": "4bdcaa41-86a5-412b-dbd5-9632de3b7387"
   },
   "outputs": [],
   "source": [
    "var_name = ['b0', 'b1', 'df']\n",
    "n_var = len(mcmc_trace)\n",
    "_, ax = plt.subplots(n_var, 1, figsize=(12, 3*n_var), sharex=True)\n",
    "for i in range(n_var):\n",
    "  ax[i].plot(mcmc_trace[i].numpy().squeeze(), alpha=.5)\n",
    "  ax[i].set_title(var_name[i])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121220,
     "status": "ok",
     "timestamp": 1553755787951,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "sUsr_knSYZJX",
    "outputId": "ead1e3ab-894e-4951-e66f-669fd7fce085"
   },
   "outputs": [],
   "source": [
    "var_name = ['b0', 'b1', 'df']\n",
    "n_var = len(mcmc_trace)\n",
    "_, ax = plt.subplots(1, 3, figsize=(12, 3))\n",
    "ax = ax.flatten()\n",
    "for i in range(n_var):\n",
    "  sns.distplot(mcmc_trace[i].numpy().flatten(), ax=ax[i])\n",
    "  ax[i].set_title(var_name[i])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 122743,
     "status": "ok",
     "timestamp": 1553755789490,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "1ChUMvMGDePV",
    "outputId": "8747b9f3-b4e5-4e3b-c51b-2b4a17aafa8a"
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "b0est, b1est = mcmc_trace[0].numpy().flatten()[-k:, None], mcmc_trace[1].numpy().flatten()[-k:, None]\n",
    "\n",
    "g, xlims, ylims = plot_hoggs(dfhoggs);\n",
    "xrange = np.linspace(xlims[0], xlims[1], 100)[None, :]\n",
    "g.axes[0][0].plot(np.tile(xrange, (k, 1)).T,\n",
    "                  (b0est + b1est*xrange).T,\n",
    "                  alpha=.25, color='r')\n",
    "plt.legend([g.axes[0][0].lines[-1]], ['MCMC StudentT model']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIbqCtohdEqR"
   },
   "source": [
    "## Hierarchical Partial Pooling\n",
    "\n",
    "From PyMC3 [baseball data for 18 players from Efron and Morris (1975)](https://docs.pymc.io/notebooks/hierarchical_partial_pooling.html#Hierarchical-Partial-Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPT1yHaDhAw1"
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('https://raw.githubusercontent.com/pymc-devs/pymc3/master/pymc3/examples/data/efron-morris-75-data.tsv',\n",
    "                     sep=\"\\t\")\n",
    "at_bats, hits = data[['At-Bats', 'Hits']].values.T\n",
    "n = len(at_bats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1553755992425,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "epbqXob8gfGb",
    "outputId": "7cd8bbc3-46c9-4b89-817b-8e5abe96fc40"
   },
   "outputs": [],
   "source": [
    "a, b = tf.cast(0, dtype), tf.cast(1, dtype)\n",
    "mdl_baseball = tfd.JointDistributionSequential([\n",
    "    # phi\n",
    "    tfd.Uniform(low=a, high=b),\n",
    "    # kappa_log\n",
    "    tfd.Exponential(rate=tf.cast(1.5, dtype)),\n",
    "    # thetas\n",
    "    lambda kappa_log, phi: tfd.Independent(\n",
    "        tfd.Beta(\n",
    "            concentration1=tf.tile((tf.exp(kappa_log)*phi)[:, None], (1, n)),\n",
    "            concentration0=tf.tile((tf.exp(kappa_log)*(1.0-phi))[:, None], (1, n)))\n",
    "    ),\n",
    "    # likelihood\n",
    "    lambda thetas: tfd.Independent(\n",
    "        tfd.Binomial(\n",
    "            total_count=tf.cast(at_bats, dtype),\n",
    "            probs=thetas\n",
    "        )), \n",
    "])\n",
    "\n",
    "mdl_baseball._resolve_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICYBPV0WgfGg"
   },
   "source": [
    "#### Forward sample (prior predictive sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8dqYuZVgfGi"
   },
   "outputs": [],
   "source": [
    "# let's draw some samples prior to training\n",
    "phi, kappa_log, thetas, y = mdl_baseball.sample(4)\n",
    "phi, kappa_log, thetas, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S47QTFmfayQM"
   },
   "source": [
    "Again, notice how if you dont use Independent you will end up with log_prob that has wrong batch_shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1553755994928,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "2Hekr-PrgfGd",
    "outputId": "c22c8bea-6195-4e5d-c033-d376c942e71e"
   },
   "outputs": [],
   "source": [
    "  # check logp\n",
    "pprint(mdl_baseball.log_prob_parts([phi, kappa_log, thetas, hits]))\n",
    "print(mdl_baseball.log_prob([phi, kappa_log, thetas, hits]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_Q_PEHEgfGo"
   },
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1553755997474,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "8l9PIYHlwMnG",
    "outputId": "b1ea9e1e-7eb0-473a-addd-4e7ad698d150"
   },
   "outputs": [],
   "source": [
    "phi, kappa_log, thetas, y = mdl_baseball.sample(1)\n",
    "\n",
    "x = tf.concat([phi, kappa_log, tf.squeeze(thetas)], 0)\n",
    "# [[x[0]], [x[1]], [x[2:]], hits]\n",
    "\n",
    "mdl_baseball.log_prob([[x[0]], [x[1]], [x[2:]], hits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNxlmglggfGp"
   },
   "outputs": [],
   "source": [
    "tfp_sigmoid = tfb.Sigmoid()\n",
    "tfp_exp = tfb.Exp()\n",
    "\n",
    "\n",
    "neg_log_p = lambda x: -tf.reduce_sum(\n",
    "        mdl_baseball.log_prob([\n",
    "            [tfp_sigmoid.forward(x[0])], \n",
    "            [tfp_exp.forward(x[1])],\n",
    "            [tfp_sigmoid.forward(x[2:])], \n",
    "            hits])\n",
    "    )\n",
    "\n",
    "def neg_log_likelihood(x):\n",
    "  return tfp.math.value_and_gradient(neg_log_p, x)\n",
    "\n",
    "\n",
    "start = tf.concat([\n",
    "    tfp_sigmoid.inverse(phi), \n",
    "    tfp_exp.inverse(kappa_log), \n",
    "    tfp_sigmoid.inverse(tf.squeeze(thetas))\n",
    "], 0)\n",
    "\n",
    "lbfgs_results = tfp.optimizer.lbfgs_minimize(\n",
    "    neg_log_likelihood,\n",
    "    num_correction_pairs=10,\n",
    "    initial_position=start,\n",
    "    tolerance=1e-50,\n",
    "    x_tolerance=1e-20,\n",
    "    max_iterations=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1541,
     "status": "ok",
     "timestamp": 1553756275686,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "snStzi-FNLt-",
    "outputId": "fe8542a2-2029-4140-ef14-e2059a9007fa"
   },
   "outputs": [],
   "source": [
    "lbfgs_results.converged.numpy(), lbfgs_results.failed.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMUvZTUAyLGg"
   },
   "source": [
    "LBFGS did not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1553756275690,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "-UNxjka5gfGr",
    "outputId": "3abb5d76-3507-4fea-a83d-1bb3cd8c806a"
   },
   "outputs": [],
   "source": [
    "map_param = lambda x: [\n",
    "            [tfp_sigmoid.forward(x[0]).numpy()], \n",
    "            [tf.exp(tfp_exp.forward(x[1])).numpy()], \n",
    "            [tfp_sigmoid.forward(x[2:]).numpy()]\n",
    "]\n",
    "\n",
    "phi_est, kappa_est, theta_est = map_param(lbfgs_results.position)\n",
    "phi_est, kappa_est, theta_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkeKsN-RgfGx"
   },
   "source": [
    "### MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 232119,
     "status": "ok",
     "timestamp": 1553755898996,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "kuT8ILmjgfGy",
    "outputId": "f39f7fc1-c9f7-4f68-84fb-6685ca5872dd"
   },
   "outputs": [],
   "source": [
    "logp = lambda phi, kappa_log, thetas: mdl_baseball.log_prob([phi, kappa_log, thetas, hits])\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def run_chain(number_of_steps = 1000, burnin = 5000, nchain = 4):\n",
    "  # random initialization of the starting postion of each chain\n",
    "  phi, kappa_log, thetas, _ = mdl_baseball.sample(nchain, n)\n",
    "\n",
    "  unconstraining_bijectors = [\n",
    "      tfp_sigmoid,\n",
    "      tfp_exp,\n",
    "      tfp_sigmoid,\n",
    "  ]\n",
    "\n",
    "  def trace_fn(_, pkr):\n",
    "    return (pkr.inner_results.inner_results.is_accepted,\n",
    "            pkr.inner_results.inner_results.accepted_results.step_size)\n",
    "\n",
    "  kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "      target_log_prob_fn=logp,\n",
    "      num_leapfrog_steps=3,\n",
    "      step_size=[tf.cast(i, dtype=dtype) for i in [.1, .1, .1]]),\n",
    "    bijector=unconstraining_bijectors)\n",
    "\n",
    "  hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    kernel,\n",
    "    target_accept_prob=tf.cast(.8, dtype=dtype),\n",
    "    # Adapt for the entirety of the trajectory.\n",
    "    num_adaptation_steps=burnin\n",
    "    )\n",
    "\n",
    "  # Sampling from the chain.\n",
    "  mcmc_trace, (is_accepted, step_size) = tfp.mcmc.sample_chain(\n",
    "      num_results = number_of_steps,\n",
    "      num_burnin_steps = burnin,\n",
    "      current_state=[phi, tf.ones_like(kappa_log, dtype=dtype), thetas],\n",
    "      kernel=hmc,\n",
    "      trace_fn=trace_fn)\n",
    "  return mcmc_trace, is_accepted, step_size\n",
    "\n",
    "# Sample from posterior distribution and get diagnostic\n",
    "mcmc_trace, is_accepted, step_size = run_chain()\n",
    "ess = tfp.mcmc.effective_sample_size(mcmc_trace)\n",
    "rhat = tfp.mcmc.potential_scale_reduction(mcmc_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 233495,
     "status": "ok",
     "timestamp": 1553755900386,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "54c5FRWazL43",
    "outputId": "ba92c003-5e97-4616-ab10-3205bd8e041e"
   },
   "outputs": [],
   "source": [
    "print(\"acceptance rate: {}\".format(is_accepted.numpy().mean()))\n",
    "print(\"final 100 step size: {}\".format(np.asarray(step_size[-100:]).mean(-1)))\n",
    "print(\"The effective sample size is: \")\n",
    "print([es.numpy() for es in ess])\n",
    "print(\"The rhat is: \")\n",
    "print([r.numpy() for r in rhat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 235618,
     "status": "ok",
     "timestamp": 1553755902521,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "nNzWXnqsgfG7",
    "outputId": "4a6a4834-4471-4044-81e1-813e7c317746"
   },
   "outputs": [],
   "source": [
    "var_name = ['phi', 'kappa_log']\n",
    "n_var = len(var_name)\n",
    "_, ax = plt.subplots(n_var, 1, figsize=(12, 3*n_var), sharex=True)\n",
    "for i in range(n_var):\n",
    "  ax[i].plot(mcmc_trace[i].numpy().squeeze(), alpha=.5)\n",
    "  ax[i].set_title(var_name[i])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 240324,
     "status": "ok",
     "timestamp": 1553755907242,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "--515870gfG-",
    "outputId": "7bf92599-fa2f-44f7-e4bf-024c94f4cc0d"
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(6, 3, figsize=(12, 12), sharex=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(n):\n",
    "  sns.distplot(mcmc_trace[-1][i].numpy().flatten(), ax=ax[i])\n",
    "  ax[i].set_title('theta %s'%i)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bU5tqkFHUYic"
   },
   "source": [
    "## Mixed effect model\n",
    "The last model in the PyMC3 doc: [A Primer on Bayesian Methods for Multilevel Modeling](https://docs.pymc.io/notebooks/multilevel_modeling.html)\n",
    "\n",
    "Some changes in prior (smaller scale etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Udlc1qnFXNJ3"
   },
   "outputs": [],
   "source": [
    "srrs2 = pd.read_csv('https://raw.githubusercontent.com/pymc-devs/pymc3/master/pymc3/examples/data/srrs2.dat')\n",
    "\n",
    "srrs2.columns = srrs2.columns.map(str.strip)\n",
    "srrs_mn = srrs2[srrs2.state=='MN'].copy()\n",
    "srrs_mn['fips'] = srrs_mn.stfips*1000 + srrs_mn.cntyfips\n",
    "\n",
    "cty = pd.read_csv('https://raw.githubusercontent.com/pymc-devs/pymc3/master/pymc3/examples/data/cty.dat')\n",
    "cty_mn = cty[cty.st=='MN'].copy()\n",
    "cty_mn[ 'fips'] = 1000*cty_mn.stfips + cty_mn.ctfips\n",
    "\n",
    "srrs_mn = srrs_mn.merge(cty_mn[['fips', 'Uppm']], on='fips')\n",
    "srrs_mn = srrs_mn.drop_duplicates(subset='idnum')\n",
    "u = np.log(srrs_mn.Uppm)\n",
    "\n",
    "n = len(srrs_mn)\n",
    "\n",
    "srrs_mn.county = srrs_mn.county.map(str.strip)\n",
    "mn_counties = srrs_mn.county.unique()\n",
    "counties = len(mn_counties)\n",
    "county_lookup = dict(zip(mn_counties, range(len(mn_counties))))\n",
    "\n",
    "county = srrs_mn['county_code'] = srrs_mn.county.replace(county_lookup).values\n",
    "radon = srrs_mn.activity\n",
    "srrs_mn['log_radon'] = log_radon = np.log(radon + 0.1).values\n",
    "floor_measure = srrs_mn.floor.values.astype('float')\n",
    "\n",
    "# Create new variable for mean of floor across counties\n",
    "xbar = srrs_mn.groupby('county')['floor'].mean().rename(county_lookup).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HU2iga4DdV3_"
   },
   "source": [
    "Batch version of a mixed effect model. It need some gymnastics to make sure the function is behave as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2267,
     "status": "ok",
     "timestamp": 1553801672089,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "tJBLSBihrMDz",
    "outputId": "78d2ca9a-dba3-48c2-bde4-85958dc79304"
   },
   "outputs": [],
   "source": [
    "mu0 = tf.zeros([], dtype, name='mu0') # hyperprior\n",
    "contextual_effect2 = tfd.JointDistributionSequential([\n",
    "    # sigma_a\n",
    "    tfd.HalfCauchy(loc=mu0, scale=5.),\n",
    "    # gamma\n",
    "    tfd.Sample(tfd.Normal(loc=mu0, scale=100.), 3),\n",
    "    # eps_a\n",
    "    lambda gamma, sigma_a: tfd.Sample(\n",
    "        tfd.Normal(loc=mu0, scale=sigma_a), counties),\n",
    "    # b\n",
    "    tfd.Normal(loc=mu0, scale=100.),\n",
    "    # sigma_y\n",
    "    tfd.HalfCauchy(loc=mu0, scale=5.),\n",
    "    # likelihood\n",
    "    lambda sigma_y, b, eps_a, gamma, sigma_a: tfd.Independent(\n",
    "        tfd.Normal(\n",
    "            # parameter transformation (linear equation), this is a long one\n",
    "            loc=(tf.transpose((gamma[..., 0]\n",
    "                             + gamma[..., 1]*u.values[:, None]\n",
    "                             + gamma[..., 2]*xbar[county][:, None]))\n",
    "                 + tf.gather(eps_a, county, axis=1)\n",
    "                 + b[..., None]*floor_measure),\n",
    "            scale=sigma_y[:, None]\n",
    "        ),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    ),\n",
    "])\n",
    "\n",
    "contextual_effect2._resolve_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inTzer00cdu2"
   },
   "source": [
    "For models with complex transformation, implementing it in a functional style would make writing and testing much easier. Also, it makes programmtically generate log_prob function that conditioned on (mini-batch) of inputted data much easier:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ogaMtI3drVX"
   },
   "outputs": [],
   "source": [
    "@tf.function(autograph=False)\n",
    "def affine(u_val, x_county, county, floor, gamma, eps, b):\n",
    "  \"\"\"Linear equation of the coefficients and the covariates, with broadcasting.\"\"\"\n",
    "  return (tf.transpose((gamma[..., 0]\n",
    "                      + gamma[..., 1]*u_val[:, None]\n",
    "                      + gamma[..., 2]*x_county[:, None]))\n",
    "          + tf.gather(eps, county, axis=1)\n",
    "          + b[..., None]*floor)\n",
    "\n",
    "\n",
    "mu0 = tf.zeros([], dtype, name='mu0') # hyperprior\n",
    "def model(u_val, x_county, county, floor):\n",
    "  \"\"\"Creates a joint distribution representing our generative process.\"\"\"\n",
    "  return tfd.JointDistributionSequential([\n",
    "      # sigma_a\n",
    "      tfd.HalfCauchy(loc=mu0, scale=5.),\n",
    "      # gamma\n",
    "      tfd.Sample(tfd.Normal(loc=mu0, scale=100.), 3),\n",
    "      # eps\n",
    "      lambda gamma, sigma_a: tfd.Sample(\n",
    "          tfd.Normal(loc=mu0, scale=sigma_a), counties),\n",
    "      # b\n",
    "      tfd.Normal(loc=mu0, scale=100.),\n",
    "      # sigma_y\n",
    "      tfd.HalfCauchy(loc=mu0, scale=5.),\n",
    "      # likelihood\n",
    "      lambda sigma_y, b, eps, gamma, sigma_a: tfd.Independent(\n",
    "          tfd.Normal(\n",
    "              loc=affine(u_val, x_county, county, floor, gamma, eps, b),\n",
    "              scale=sigma_y[:, None]\n",
    "          ),\n",
    "          reinterpreted_batch_ndims=1\n",
    "      ),\n",
    "  ])\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def unnormalized_posterior_log_prob(sigma_a, gamma, eps, b, sigma_y):\n",
    "  \"\"\"Computes `joint_log_prob` pinned at `log_radon`.\"\"\"\n",
    "  return model(u.values,  xbar[county], county, floor_measure).log_prob(\n",
    "      [sigma_a, gamma, eps, b, sigma_y, log_radon])\n",
    "\n",
    "assert [4] == unnormalized_posterior_log_prob(\n",
    "    *contextual_effect2.sample(4)[:-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2106,
     "status": "ok",
     "timestamp": 1553801672091,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "wCY07JiEKUmO",
    "outputId": "8d2c7c47-0661-460e-d048-142cdea30a35"
   },
   "outputs": [],
   "source": [
    "samples = contextual_effect2.sample(4)\n",
    "pprint([s.shape for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1864,
     "status": "ok",
     "timestamp": 1553801672093,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "xzSxMiunreZH",
    "outputId": "9e9ad3fb-0b79-4f97-a1c9-5fc4d11a16c5"
   },
   "outputs": [],
   "source": [
    "contextual_effect2.log_prob_parts(list(samples)[:-1] + [log_radon])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNfvyzlbNVvn"
   },
   "source": [
    "### Variational Inference\n",
    "\n",
    "One very powerful feature of `JointDistribution` is that you can generate an approximation easily for VI. For example, to do meanfield ADVI, you simply inspect the graph and replace all the none observed distribution with a Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfRCDXKogwl2"
   },
   "outputs": [],
   "source": [
    "from tensorflow_probability.python.mcmc.transformed_kernel import forward_log_det_jacobian_fn\n",
    "from tensorflow_probability.python.mcmc.transformed_kernel import forward_transform_fn\n",
    "from tensorflow_probability.python.mcmc.transformed_kernel import inverse_transform_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhdKqa49jDap"
   },
   "outputs": [],
   "source": [
    "hparams = dict(\n",
    "    init_raw_scale=np.log(np.expm1(1.)),  # approx= 0.5413\n",
    "    scale_diag_offset=1e-3,\n",
    "    \n",
    "    num_monte_carlo_draws=10,\n",
    "\n",
    "    train_iterations = int(1e4),\n",
    "\n",
    "    learning_rate_start = 1e-2,\n",
    "    learning_rate_num_epochs_per_decay = 10,\n",
    "    learning_rate_decay_factor = 0.99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1474,
     "status": "ok",
     "timestamp": 1553801672599,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "t5AMrT-xYAkZ",
    "outputId": "f5f77973-9d99-4655-f433-d3f903496ad5"
   },
   "outputs": [],
   "source": [
    "# wrap logp so that all parameters are in R\n",
    "# copied from tensorflow_probability/python/mcmc/transformed_kernel.py\n",
    "unconstraining_bijectors = [\n",
    "    tfb.Exp(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Exp()\n",
    "]\n",
    "\n",
    "_forward_transform = forward_transform_fn(unconstraining_bijectors)\n",
    "_forward_log_det_jacobian = forward_log_det_jacobian_fn(unconstraining_bijectors)\n",
    "_inverse_transform = inverse_transform_fn(unconstraining_bijectors)\n",
    "\n",
    "unnormalized_log_prob = lambda input_list: contextual_effect2.log_prob(\n",
    "    list(input_list) + [log_radon])\n",
    "\n",
    "def contextual_effect_posterior(transformed_state_parts):\n",
    "  \"\"\"Log prob of the transformed state.\"\"\"\n",
    "  # TODO(b/72831017): Use `tf.identity` to disable caching (since HMC takes\n",
    "  # gradient with respect to input).\n",
    "  transformed_state_parts = [\n",
    "      tf.identity(sp) for sp in transformed_state_parts\n",
    "  ]\n",
    "  tlp = unnormalized_log_prob(\n",
    "      _forward_transform(transformed_state_parts))\n",
    "  event_ndims = [\n",
    "      tf.rank(sp) - tf.rank(tlp) for sp in transformed_state_parts\n",
    "  ]\n",
    "  return tlp + _forward_log_det_jacobian(\n",
    "      transformed_state_parts=transformed_state_parts,\n",
    "      event_ndims=event_ndims)\n",
    "\n",
    "# Check the two versions of log_prob - they should be different given the Jacobian\n",
    "rv_samples = contextual_effect2.sample(4)\n",
    "\n",
    "pprint([\n",
    "    unnormalized_log_prob(rv_samples[:-1]),\n",
    "    contextual_effect_posterior(_inverse_transform(rv_samples[:-1])),\n",
    "    unnormalized_log_prob(\n",
    "        _forward_transform(\n",
    "            tf.zeros_like(a, dtype=dtype) for a in rv_samples[:-1])\n",
    "    ),\n",
    "    contextual_effect_posterior(\n",
    "        [tf.zeros_like(a, dtype=dtype) for a in rv_samples[:-1]]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9RVGf5zvEwZ"
   },
   "source": [
    "#### Meanfield ADVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_PlWfMloiV1U"
   },
   "outputs": [],
   "source": [
    "# Build meanfield ADVI for a jointdistribution\n",
    "# Inspect the input jointdistribution and replace the list of distribution with\n",
    "# a list of Normal distribution, each with the same shape.\n",
    "def gen_params_meanfield(jd, observed_node=-1):\n",
    "  \"\"\"\n",
    "  The inputted jointdistribution needs to be a batch version\n",
    "  \"\"\"\n",
    "  # sample to get a list of samples\n",
    "  list_of_values = list(jd.sample(1))  # <== sample=() would not work\n",
    "  \n",
    "  # remove the observed node\n",
    "  list_of_values.pop(observed_node)\n",
    "  \n",
    "  # iterate sample to a build a list of parameters for Normal\n",
    "  free_param = []\n",
    "  for i, value in enumerate(list_of_values):\n",
    "    dtype = value.dtype\n",
    "    rv_shape = value[0].shape\n",
    "    loc = tf.Variable(\n",
    "        tf.random.normal(rv_shape, dtype=dtype),\n",
    "        name='meanfield_%s_mu' % i,\n",
    "        dtype=dtype)\n",
    "    rho = tf.Variable(\n",
    "        tf.random.normal(rv_shape, dtype=dtype),\n",
    "        name='meanfield_%s_rho' % i,\n",
    "        dtype=dtype)\n",
    "    free_param.append([loc, rho])\n",
    "  return free_param\n",
    "\n",
    "def build_meanfield_advi(param):\n",
    "  distlist = []\n",
    "  for loc, rho in param:\n",
    "    approx_node = tfd.Normal(loc=loc, scale=tf.nn.softplus(rho))\n",
    "    if loc.shape == ():\n",
    "      distlist.append(approx_node)\n",
    "    else:\n",
    "      distlist.append(\n",
    "          # TODO: make the reinterpreted_batch_ndims more flexible (for \n",
    "          # minibatch etc)\n",
    "          tfd.Independent(approx_node, reinterpreted_batch_ndims=1)\n",
    "      )\n",
    "\n",
    "  # pass list to JointDistribution to initiate the meanfield advi\n",
    "  meanfield_advi = tfd.JointDistributionSequential(distlist)\n",
    "  return meanfield_advi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1553801672602,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "0OkKoVUUjWqw",
    "outputId": "85563b35-3394-4461-b398-f3d3d91ce203"
   },
   "outputs": [],
   "source": [
    "free_param = gen_params_meanfield(contextual_effect2, observed_node=-1)\n",
    "advi = build_meanfield_advi(free_param)\n",
    "\n",
    "\n",
    "# Check the logp and logq\n",
    "advi_samples = advi.sample(4)\n",
    "contextual_effect_posterior(advi_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1553801673075,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "ad3tgy78XvZu",
    "outputId": "3690000b-708a-4365-c450-624639de9e53"
   },
   "outputs": [],
   "source": [
    "advi.reparameterization_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1476,
     "status": "ok",
     "timestamp": 1553801973530,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "tmXNoaS5S1y4",
    "outputId": "31744b22-a423-47a0-8439-76ab8b1e4a5a"
   },
   "outputs": [],
   "source": [
    "def elbo_loss():\n",
    "  advi = build_meanfield_advi(free_param)\n",
    "  return tfp.vi.monte_carlo_csiszar_f_divergence(\n",
    "    f=tfp.vi.kl_reverse,  # same as: Evidence Lower BOund\n",
    "    p_log_prob=contextual_effect_posterior,\n",
    "    q=advi,\n",
    "    num_draws=hparams['num_monte_carlo_draws'],\n",
    "    name='elbo_loss')\n",
    "print(elbo_loss)\n",
    "\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=hparams['learning_rate_start'],\n",
    "    decay_steps=hparams['learning_rate_num_epochs_per_decay'],\n",
    "    decay_rate=hparams['learning_rate_decay_factor'],\n",
    "    staircase=True)\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 291895,
     "status": "ok",
     "timestamp": 1553802264091,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "REQk_UnyrNbw",
    "outputId": "e6a6884f-4d85-4972-e2a3-0e7e2f8b3ca2"
   },
   "outputs": [],
   "source": [
    "loss_ = np.zeros(hparams['train_iterations'])\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def train():\n",
    "  opt.minimize(elbo_loss, var_list=free_param)\n",
    "  return elbo_loss()\n",
    "\n",
    "for iter_ in range(hparams['train_iterations']):\n",
    "  loss_[iter_] = train()\n",
    "  if iter_ % 1000 == 0 or iter_ == hparams['train_iterations'] - 1:\n",
    "    print(\"iter:{:>4}  loss:{:.3f}\".format(iter_, loss_[iter_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4Weyjvhllc4"
   },
   "source": [
    "Note: the above is sensitive to initialization - simply reexcute the cell if the result does not look converged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1553802720401,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "Q-Tkb_fFZdwO",
    "outputId": "7dc452ee-2820-4f96-f078-e45eb8038bf4"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_);\n",
    "plt.xlabel('iter');\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkpyOxJLSU-H"
   },
   "outputs": [],
   "source": [
    "graph_info = contextual_effect2._resolve_graph()\n",
    "approx_param = dict()\n",
    "for i, (rvname, param) in enumerate(graph_info[:-1]):\n",
    "  approx_param[rvname] = {\"mu\": free_param[i][0].numpy(),\n",
    "                          \"sd\": tf.nn.softplus(free_param[i][1]).numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1553802829140,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "hfcW-Sbacvp7",
    "outputId": "11017f26-2f8e-45f5-8cfd-7bff33aee208"
   },
   "outputs": [],
   "source": [
    "approx_param.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1553802829691,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "rBcWtUHrgJGY",
    "outputId": "5f4354e9-a4e0-4583-cf47-0032d7370c35"
   },
   "outputs": [],
   "source": [
    "approx_param['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1655,
     "status": "ok",
     "timestamp": 1553802888335,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "il__s8_9aUr5",
    "outputId": "f44b842e-5526-48bf-a2c8-86525e057824"
   },
   "outputs": [],
   "source": [
    "a_means = (approx_param['gamma']['mu'][0] \n",
    "         + approx_param['gamma']['mu'][1]*u.values\n",
    "#          + approx_param['gamma']['mu'][2]*xbar[county]\n",
    "         + approx_param['eps_a']['mu'][county])\n",
    "_, index = np.unique(county, return_index=True)\n",
    "plt.scatter(u.values[index], a_means[index], color='g')\n",
    "\n",
    "xvals = np.linspace(-1, 0.8)\n",
    "plt.plot(xvals, \n",
    "         approx_param['gamma']['mu'][0]+approx_param['gamma']['mu'][1]*xvals, \n",
    "         'k--')\n",
    "plt.xlim(-1, 0.8)\n",
    "\n",
    "plt.xlabel('County-level uranium');\n",
    "plt.ylabel('Intercept estimate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2052,
     "status": "ok",
     "timestamp": 1553802895465,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "OjiUsY3BgW9M",
    "outputId": "4ca0fff2-5013-43c9-e8a9-07a333887e37"
   },
   "outputs": [],
   "source": [
    "y_est = (approx_param['gamma']['mu'][0] \n",
    "         + approx_param['gamma']['mu'][1]*u.values\n",
    "         + approx_param['gamma']['mu'][2]*xbar[county]\n",
    "         + approx_param['eps_a']['mu'][county]\n",
    "         + approx_param['b']['mu']*floor_measure)\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(county, log_radon, 'o', alpha=.25, label='observed')\n",
    "ax.plot(county, y_est, '-o', lw=2, alpha=.5, label='y_hat')\n",
    "ax.set_xlim(-1, county.max()+1)\n",
    "plt.legend(loc='lower right')\n",
    "ax.set_xlabel('County #')\n",
    "ax.set_ylabel('log(Uranium) level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lm1F6WXScL89"
   },
   "source": [
    "#### (Structured) FullRank ADVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRCjDloZcO1g"
   },
   "outputs": [],
   "source": [
    "def gen_params_fullrank(jd, observed_node=-1, rank='full'):\n",
    "  # sample to get a list of samples\n",
    "  list_of_values = list(jd.sample(1))  # <== sample=() would not work\n",
    "  \n",
    "  # remove the observed node\n",
    "  list_of_values.pop(observed_node)\n",
    "  \n",
    "  # iterate sample to a build a list of parameters for Normal or MvNormal\n",
    "  free_param = []\n",
    "  for i, value in enumerate(list_of_values):\n",
    "    dtype = value.dtype\n",
    "    rv_shape = value[0].shape\n",
    "    if rv_shape == (): # scalar case\n",
    "      loc=tf.Variable(\n",
    "          tf.random.normal(rv_shape, dtype=dtype),\n",
    "          name='lowrank_%s_mu' % i,\n",
    "          dtype=dtype)\n",
    "      rho = tf.Variable(\n",
    "          tf.zeros(rv_shape, dtype=dtype),\n",
    "          name='lowrank_%s_rho' % i,\n",
    "          dtype=dtype)\n",
    "      free_param.append([loc, rho])\n",
    "    else: # None scalar RVs\n",
    "      ndim = np.prod(rv_shape.as_list())\n",
    "      loc = tf.Variable(\n",
    "          tf.random.normal([ndim], dtype=dtype),\n",
    "          name='lowrank_%s_mu' % i,\n",
    "          dtype=dtype)\n",
    "      \n",
    "      if rank == 'full': # full rank\n",
    "        raw_scale_tril = tf.Variable(\n",
    "          tf.zeros([ndim * (ndim + 1) // 2], dtype=dtype),\n",
    "          name='lowrank_%s_tril' % i,\n",
    "          dtype=dtype)\n",
    "        free_param.append([loc, raw_scale_tril])\n",
    "      else: # low rank\n",
    "        rank = 1\n",
    "        raw_scale = tf.Variable(\n",
    "          tf.zeros([ndim * (1 + rank)], dtype=dtype),\n",
    "          name='lowrank_%s_scale' % i,\n",
    "          dtype=dtype)\n",
    "        free_param.append([loc, raw_scale])\n",
    "  \n",
    "  return free_param\n",
    "\n",
    "def build_structure_advi(param, rank='full'):\n",
    "  distlist = []\n",
    "  for loc, cov_info in param:\n",
    "    if loc.shape == ():\n",
    "      approx_node = tfd.Normal(loc=loc, scale=tf.nn.softplus(cov_info))\n",
    "    else:\n",
    "      if rank == 'full': # full rank\n",
    "        scale_tril = tfd.fill_triangular(cov_info)\n",
    "        new_diag = hparams['scale_diag_offset'] + tf.nn.softplus(\n",
    "          hparams['init_raw_scale'] + tf.diag_part(scale_tril))\n",
    "        scale_tril = tf.linalg.set_diag(scale_tril, new_diag)\n",
    "        approx_node = tfd.MultivariateNormalTriL(\n",
    "          loc=loc,\n",
    "          scale_tril=scale_tril)\n",
    "      else: # low rank\n",
    "        lower_rank = 1\n",
    "        ndim = tf.shape(loc)[0]\n",
    "        approx_node = tfd.MultivariateNormalDiagPlusLowRank(\n",
    "          loc=loc,\n",
    "          scale_diag=tf.nn.softplus(hparams['init_raw_scale'] + cov_info[:ndim]),\n",
    "          scale_perturb_factor=tf.reshape(cov_info[ndim:], [ndim, lower_rank]))\n",
    "    distlist.append(approx_node)\n",
    "    \n",
    "  # pass list to JointDistribution to initiate the fullrank advi\n",
    "  structure_advi = tfd.JointDistributionSequential(distlist)\n",
    "  return structure_advi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 306672,
     "status": "ok",
     "timestamp": 1553851035511,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "Eb0XNOxDBOVR",
    "outputId": "beb2ec50-59f1-43e9-f390-c28bca2d1198"
   },
   "outputs": [],
   "source": [
    "free_param = gen_params_fullrank(contextual_effect2, observed_node=-1, rank='low')\n",
    "lowrank_advi = build_structure_advi(free_param, rank='low')\n",
    "\n",
    "\n",
    "# Check the logp and logq\n",
    "advi_samples = lowrank_advi.sample(4)\n",
    "contextual_effect_posterior(advi_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 306484,
     "status": "ok",
     "timestamp": 1553851035512,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "nL_LM9oEGKtV",
    "outputId": "3ec6b736-794c-49b9-acf3-82f76f761d11"
   },
   "outputs": [],
   "source": [
    "def elbo_loss():\n",
    "  lowrank_advi = build_structure_advi(free_param, rank='low')\n",
    "  return tfp.vi.monte_carlo_csiszar_f_divergence(\n",
    "    f=tfp.vi.kl_reverse,  # same as: Evidence Lower BOund\n",
    "    p_log_prob=contextual_effect_posterior,\n",
    "    q=lowrank_advi,\n",
    "    num_draws=hparams['num_monte_carlo_draws'],\n",
    "    name='elbo_loss')\n",
    "print(elbo_loss)\n",
    "\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=hparams['learning_rate_start'],\n",
    "    decay_steps=hparams['learning_rate_num_epochs_per_decay'],\n",
    "    decay_rate=hparams['learning_rate_decay_factor'],\n",
    "    staircase=True)\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 653570,
     "status": "ok",
     "timestamp": 1553851383168,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "l_qrG3VuGKtx",
    "outputId": "58da5e0d-e4c8-439e-c26b-25376d73c65b"
   },
   "outputs": [],
   "source": [
    "loss_ = np.zeros(hparams['train_iterations'])\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def train():\n",
    "  opt.minimize(elbo_loss, var_list=free_param)\n",
    "  return elbo_loss()\n",
    "\n",
    "for iter_ in range(hparams['train_iterations']):\n",
    "  loss_[iter_] = train()\n",
    "  if iter_ % 1000 == 0 or iter_ == hparams['train_iterations'] - 1:\n",
    "    print(\"iter:{:>4}  loss:{:.3f}\".format(iter_, loss_[iter_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 653561,
     "status": "ok",
     "timestamp": 1553851383593,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "uofCD_J43moW",
    "outputId": "a4082626-0042-4900-fb11-8461211b5d01"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_);\n",
    "plt.xlabel('iter');\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lndt-B20Gmjr"
   },
   "outputs": [],
   "source": [
    "graph_info = contextual_effect2._resolve_graph()\n",
    "approx_param = dict()\n",
    "for i, (rvname, param) in enumerate(graph_info[:-1]):\n",
    "  approx_param[rvname] = {\"mu\": free_param[i][0].numpy(),\n",
    "                          \"cov_info\": free_param[i][1].numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651941,
     "status": "ok",
     "timestamp": 1553851383604,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "VqE0FH453mok",
    "outputId": "cde25c26-0895-48f0-bf83-8e0a7ca1b2a7"
   },
   "outputs": [],
   "source": [
    "approx_param.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651389,
     "status": "ok",
     "timestamp": 1553851383605,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "M29K1ciu3mon",
    "outputId": "247d132f-2f34-45b5-aaa8-ccf978003569"
   },
   "outputs": [],
   "source": [
    "approx_param['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 652332,
     "status": "ok",
     "timestamp": 1553851385053,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "aVwYswkj3mot",
    "outputId": "1fe594cf-e284-4560-f8d2-255910162ee9"
   },
   "outputs": [],
   "source": [
    "a_means = (approx_param['gamma']['mu'][0] \n",
    "         + approx_param['gamma']['mu'][1]*u.values\n",
    "#          + approx_param['gamma']['mu'][2]*xbar[county]\n",
    "         + approx_param['eps_a']['mu'][county])\n",
    "_, index = np.unique(county, return_index=True)\n",
    "plt.scatter(u.values[index], a_means[index], color='g')\n",
    "\n",
    "xvals = np.linspace(-1, 0.8)\n",
    "plt.plot(xvals, \n",
    "         approx_param['gamma']['mu'][0]+approx_param['gamma']['mu'][1]*xvals, \n",
    "         'k--')\n",
    "plt.xlim(-1, 0.8)\n",
    "\n",
    "plt.xlabel('County-level uranium');\n",
    "plt.ylabel('Intercept estimate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651941,
     "status": "ok",
     "timestamp": 1553851385056,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "N204j2Kx3mow",
    "outputId": "0fc3897a-c069-4d15-9494-e7b124107004"
   },
   "outputs": [],
   "source": [
    "y_est = (approx_param['gamma']['mu'][0] \n",
    "         + approx_param['gamma']['mu'][1]*u.values\n",
    "         + approx_param['gamma']['mu'][2]*xbar[county]\n",
    "         + approx_param['eps_a']['mu'][county]\n",
    "         + approx_param['b']['mu']*floor_measure)\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(county, log_radon, 'o', alpha=.25, label='observed')\n",
    "ax.plot(county, y_est, '-o', lw=2, alpha=.5, label='y_hat')\n",
    "ax.set_xlim(-1, county.max()+1)\n",
    "plt.legend(loc='lower right')\n",
    "ax.set_xlabel('County #')\n",
    "ax.set_ylabel('log(Uranium) level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHP-_EGFgZfp"
   },
   "source": [
    "## Beta-Bernoulli Mixture Model\n",
    "\n",
    "A mixture model where multiple reviewer labeling some items, with unknown (true) latent labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4c5nHUtdE8f"
   },
   "outputs": [],
   "source": [
    "n = 50000    # number of examples reviewed\n",
    "p_bad_ = 0.1 # fraction of bad events\n",
    "m = 5        # number of reviewers for each example\n",
    "rcl_ = .35 + np.random.rand(m)/10\n",
    "prc_ = .65 + np.random.rand(m)/10\n",
    "\n",
    "# PARAMETER TRANSFORMATION\n",
    "tpr = rcl_\n",
    "fpr = p_bad_*tpr*(1./prc_-1.)/(1.-p_bad_)\n",
    "tnr = 1 - fpr\n",
    "\n",
    "# broadcast to m reviewer.\n",
    "batch_prob = np.asarray([tpr, fpr]).T\n",
    "mixture = tfd.Mixture(\n",
    "    tfd.Categorical(\n",
    "        probs=[tf.cast(p_bad_, dtype),\n",
    "               1-tf.cast(p_bad_, dtype)]),\n",
    "    [\n",
    "        tfd.Independent(tfd.Bernoulli(probs=tf.cast(tpr, dtype)), \n",
    "                        reinterpreted_batch_ndims=1),\n",
    "        tfd.Independent(tfd.Bernoulli(probs=tf.cast(fpr, dtype)), \n",
    "                        reinterpreted_batch_ndims=1),\n",
    "    ])\n",
    "# Generate reviewer response\n",
    "X_tf = mixture.sample([n])\n",
    "\n",
    "# run once to always use the same array as input\n",
    "# so we can compare the estimation from different\n",
    "# inference method.\n",
    "X_np = X_tf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2186,
     "status": "ok",
     "timestamp": 1553848863041,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "SCu4tFG8japm",
    "outputId": "77c3ff63-2779-4ed2-ea51-9dff61a81556"
   },
   "outputs": [],
   "source": [
    "# batched Mixture model\n",
    "mdl_mixture = tfd.JointDistributionSequential([\n",
    "    # prc\n",
    "    tfd.Independent(\n",
    "        tfd.Beta(concentration1=tf.ones(m, dtype)*5., \n",
    "                 concentration0=2.),\n",
    "        reinterpreted_batch_ndims=1,\n",
    "    ), \n",
    "    # rcl prior\n",
    "    tfd.Independent(\n",
    "        tfd.Beta(concentration1=tf.ones(m, dtype)*2.,\n",
    "                 concentration0=2.),\n",
    "        reinterpreted_batch_ndims=1,\n",
    "    ),\n",
    "    # badness prior\n",
    "    tfd.Beta(concentration1=tf.cast(1., dtype), \n",
    "             concentration0=10.),\n",
    "    # likelihood\n",
    "    #   We have a repeated measure at the end, and it could be quite difficult\n",
    "    #   to get the shape right. Luckly we have a new shape handling distribution\n",
    "    #   wrapper to do that: tfd.Sample\n",
    "    lambda p_bad, rcl, prc: tfd.Sample(tfd.Mixture(\n",
    "        tfd.Categorical(\n",
    "            probs=tf.transpose(tf.concat(([p_bad], [1-p_bad]), axis=0))\n",
    "        ),\n",
    "        [\n",
    "            tfd.Independent(\n",
    "                tfd.Bernoulli(probs=rcl), \n",
    "                reinterpreted_batch_ndims=1\n",
    "            ),\n",
    "            tfd.Independent(\n",
    "                tfd.Bernoulli(\n",
    "                    probs=p_bad[:, None]*rcl*(1./prc-1.)/(1.-p_bad[:, None])),\n",
    "                reinterpreted_batch_ndims=1\n",
    "            )\n",
    "        ]\n",
    "    ), (n, )), \n",
    "])\n",
    "\n",
    "mdl_mixture._resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "da7oRee8pV6G"
   },
   "outputs": [],
   "source": [
    "prc, rcl, p_bad, x = mdl_mixture.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1553848863654,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "CUUtWyp2dYGq",
    "outputId": "910b78e8-15a1-4285-b586-c9396d74b116"
   },
   "outputs": [],
   "source": [
    "mdl_mixture.log_prob_parts([prc, rcl, p_bad, X_np[np.newaxis, :, :]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9_ysa6bJZKz"
   },
   "source": [
    "#### Inference (HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FiHdBn8EJZK0"
   },
   "outputs": [],
   "source": [
    "# Define a closure over our joint_log_prob. Note also that we are using the\n",
    "# batched version logp function to have multi-chain sampling\n",
    "@tf.function(autograph=False)\n",
    "def run_chain(number_of_steps = 1000, burnin = 5000, nchain = 4):\n",
    "  # Set the chain's start state.\n",
    "  prc, rcl, p_bad, _ = mdl_mixture.sample(nchain)\n",
    "  initial_chain_state = [prc, rcl, p_bad]\n",
    "\n",
    "  # Since MCMC operates over unconstrained space, we need to transform the\n",
    "  # samples so they live in real-space.\n",
    "  unconstraining_bijectors = [\n",
    "      tfb.Sigmoid(),       # Maps R to [0, 1].\n",
    "      tfb.Sigmoid(),       # Maps R to [0, 1].\n",
    "      tfb.Sigmoid(),       # Maps R to [0, 1].\n",
    "  ]\n",
    "\n",
    "  def trace_fn(_, pkr):\n",
    "    return (pkr.inner_results.inner_results.is_accepted,\n",
    "            pkr.inner_results.inner_results.accepted_results.step_size)\n",
    "\n",
    "  kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "      target_log_prob_fn=lambda prc, rcl, p_bad: mdl_mixture.log_prob(\n",
    "          [prc, rcl, p_bad, X_np[np.newaxis, :, :]]),\n",
    "      num_leapfrog_steps=3,\n",
    "      step_size=[tf.cast(i, dtype=dtype) for i in [1e-3, 1e-3, 1e-3]]),\n",
    "    bijector=unconstraining_bijectors)\n",
    "\n",
    "  hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    kernel,\n",
    "    target_accept_prob=tf.cast(.8, dtype=dtype),\n",
    "    # Adapt for the entirety of the trajectory.\n",
    "    num_adaptation_steps=burnin\n",
    "    )\n",
    "\n",
    "  # Sampling from the chain.\n",
    "  mcmc_trace, (is_accepted, step_size) = tfp.mcmc.sample_chain(\n",
    "      num_results = number_of_steps,\n",
    "      num_burnin_steps = burnin,\n",
    "      current_state=initial_chain_state,\n",
    "      kernel=hmc,\n",
    "      trace_fn=trace_fn)\n",
    "\n",
    "  return mcmc_trace, is_accepted, step_size\n",
    "\n",
    "# Sample from posterior distribution and get diagnostic\n",
    "mcmc_trace, is_accepted, step_size = run_chain()\n",
    "ess = tfp.mcmc.effective_sample_size(mcmc_trace)\n",
    "rhat = tfp.mcmc.potential_scale_reduction(mcmc_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 287754,
     "status": "ok",
     "timestamp": 1553849749705,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "amcaMV2bKfEH",
    "outputId": "a0cf43ae-1281-4093-943e-3b4f63fef978"
   },
   "outputs": [],
   "source": [
    "print(\"acceptance rate: {}\".format(is_accepted.numpy().mean()))\n",
    "print(\"final 100 step size: {}\".format(np.asarray(step_size[-100:]).mean(-1)))\n",
    "print(\"The effective sample size is: \")\n",
    "pprint([es.numpy() for es in ess])\n",
    "print(\"The rhat is: \")\n",
    "pprint([r.numpy() for r in rhat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292123,
     "status": "ok",
     "timestamp": 1553849754508,
     "user": {
      "displayName": "Junpeng Lao",
      "photoUrl": "https://lh3.googleusercontent.com/-Q9zgzA2iUEM/AAAAAAAAAAI/AAAAAAAAABA/SVqU32lTFiw/s64/photo.jpg",
      "userId": "15196721641840344885"
     },
     "user_tz": -60
    },
    "id": "4HxM6RnFJZK6",
    "outputId": "accae25f-4de6-458e-9bd0-4b707affc6f6"
   },
   "outputs": [],
   "source": [
    "var_name = ['Precision', 'Recall', 'Badness Rate']\n",
    "true_val = [prc_, rcl_, [p_bad_]]\n",
    "n_var = len(mcmc_trace)\n",
    "_, ax = plt.subplots(n_var, 1, figsize=(12, 3*n_var), sharex=True)\n",
    "for i in range(n_var):\n",
    "  trace_val = mcmc_trace[i].numpy()\n",
    "  if trace_val.ndim > 2:\n",
    "    trace_val = trace_val.reshape(-1, trace_val.shape[-1])\n",
    "  else:\n",
    "    trace_val = trace_val.flatten()\n",
    "  ax[i].plot(trace_val, alpha=.5)\n",
    "  [ax[i].axhline(k, lw=2, alpha=.5) for k in true_val[i]]\n",
    "  ax[i].set_title(var_name[i])\n",
    "plt.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-9_ysa6bJZKz"
   ],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "Modeling_with_JointDistribution.ipynb",
   "provenance": [
    {
     "file_id": "1KnuTjdi8udCLZDfe9hufjFg01FXDLYHQ",
     "timestamp": 1550986742534
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
